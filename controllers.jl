include("POMG.jl")
include("multi_caregiver.jl")

mutable struct ControllerPolicy
    ğ’«   # problem
    X   # set of controller nodes
    Ïˆ   # action selection distribution
    Î·   # successor selection distribution
end

joint_action(x) = vec(collect(Iterators.product(x...)))
#joint_action(x) = [(e, e) for e in x[1]]
joint_observation(x) = [(e, e) for e in x[1]]

function(Ï€::ControllerPolicy)(x)
    ğ’œ, Ïˆ = joint_action(Ï€.ğ’«.ğ’œ), Ï€.Ïˆ
    dist = [Ïˆ[x, a] for a in ğ’œ] 
    return rand(SetCategorical(ğ’œ, dist))    
end
    
function update(Ï€::ControllerPolicy,x,a,o)
    X,Î· = Ï€.X, Ï€.Î·
    dist = [Î·[x, a, o, xâ€²] for xâ€² in X] 
    return rand(SetCategorical(X, dist))
end




function utility(Ï€::ControllerPolicy, U, x, s)
    ğ’®, ğ’œ, ğ’ª = Ï€.ğ’«.ğ’®, joint_action(Ï€.ğ’«.ğ’œ), joint_observation(Ï€.ğ’«.ğ’ª)
    T, O, R, Î³ = Ï€.ğ’«.T, Ï€.ğ’«.O, Ï€.ğ’«.R, Ï€.ğ’«.Î³
    X, Ïˆ, Î· = vec(collect(Iterators.product(Ï€.X...))), Ï€.Ïˆ, Ï€.Î·
    â„ = Ï€.ğ’«.â„

    Î·â€²(x, a, o, xâ€²) = prod(Î·[i][x, a, o, xâ€²] for i in â„)
    Uâ€²(a, sâ€², o) = sum(Î·â€²(x, a, o, xâ€²) * U[xâ€²,sâ€²] for xâ€² in X)
    Uâ€²(a,sâ€²) = T(s, a, sâ€²) * sum(O(a, sâ€², o) * Uâ€²(a, sâ€², o) for o in ğ’ª)
    Uâ€²(a) = sum(R(s, a)) + Î³ * sum(Uâ€²(a, sâ€²) for sâ€² in ğ’®)

    Ïˆâ€²(x,a) = prod(Î·[i][x,a] for i in â„)
    return sum(Ïˆâ€²(x,a)*Uâ€²(a) for a in ğ’œ)
end

function iterative_policy_evaluation(Ï€::ControllerPolicy, k_max)
    ğ’®, X = Ï€.ğ’«.ğ’®, vec(collect(Iterators.product(Ï€.X...)))
    U = Dict((x,s) => 0.0 for x in X, s in ğ’®) 
    for k in 1:k_max
        U = Dict((x, s) => utility(Ï€, U, x, s) for x in X, s in ğ’®)
    end
    return U 
end


struct ControllerPolicyIteration
    k_max   # number of iterations
    eval_max # number of evaluation iterations
end


function lookahead(ğ’«::POMG, U, s, a)
    ğ’®,ğ’ª,T,O,R,Î³=ğ’«.ğ’®,joint_observation(ğ’«.ğ’ª),ğ’«.T,ğ’«.O,ğ’«.R,ğ’«.Î³
    uâ€²= sum(T(s,a,sâ€²)*sum(O(a,sâ€²,o)*U(o,sâ€²) for o in ğ’ª) for sâ€² in ğ’®)
    return sum(R(s,a))+Î³*uâ€²
end

function policy_improvement!(Ï€::ControllerPolicy, U, prevX)
    ğ’®, ğ’œ, ğ’ª = Ï€.ğ’«.ğ’®, Ï€.ğ’«.ğ’œ, Ï€.ğ’«.ğ’ª
    X, Ïˆ, Î·, â„ = Ï€.X, Ï€.Ïˆ, Ï€.Î·, Ï€.â„

    
    repeatXğ’ª = [fill(X[i],length(ğ’ª[i])) for i in â„]
    assignğ’œXâ€² = [vec(collect(Iterators.product(ğ’œ[i],repeatXğ’ª[i]...))) for i in â„]
    
    for i in â„
        for x in assignğ’œXâ€²
            push!(X[i],x)
        end
    end

    for ax in Iterators.product(assignğ’œXâ€²...)
        x1, a1 = [maximum(X[1]) + 1], axâ€²1[1]
        
        push!(X[1],x1)
        push!(X[2],x2)
        successor(o) = [axâ€²1[findfirst(isequal(o),ğ’ª[1])+1], axâ€²2[findfirst(isequal(o),ğ’ª[2])+1]]
        Uâ€²(o, sâ€²) = U[successor(o),sâ€²]
        for s in ğ’®
            U[[x1, x2],s]=lookahead(Ï€.ğ’«,Uâ€²,s,[a1, a2])
        end
        for aâ€²1 in ğ’œ[1], aâ€²2 in ğ’œ[2]
            aâ€² = [aâ€²1, aâ€²2]
            Ïˆ[x,aâ€²]= aâ€²== [a1, a2] ? 1.0 : 0.0
            for (o,xâ€²) in Iterators.product(ğ’ª,prevX)
                Î·[x,aâ€²,o,xâ€²]= xâ€²== successor(o) ? 1.0 : 0.0
            end
        end
    end
    for (x, a, o, xâ€²) in Iterators.product(X, joint_action(ğ’œ), joint_observation(ğ’ª), X)
        if !haskey(Î·, (x,a,o,xâ€²))
            Î·[x,a,o,xâ€²] = 0.0
        end
    end
end

function prune!(Ï€::ControllerPolicy, U, prevX)
    ğ’®, ğ’œ, ğ’ª, X, Ïˆ, Î· = Ï€.ğ’«.ğ’®, joint_action(Ï€.ğ’«.ğ’œ), joint_observation(Ï€.ğ’«.ğ’ª), Ï€.X, Ï€.Ïˆ, Ï€.Î·
    newX, removeX = setdiff(X,prevX), []
    # prune dominated from previous nodes
    dominated(x,xâ€²) = all(U[x, s] â‰¤ U[xâ€², s] for s in ğ’®)
    for (x,xâ€²) in Iterators.product(prevX, newX)
        if xâ€² âˆ‰ removeX && dominated(x, xâ€²)
            for s in ğ’®
                U[x, s]=U[xâ€², s]
            end
            for a in ğ’œ 
                Ïˆ[x, a] = Ïˆ[xâ€², a]
                for (o,xâ€²â€²) in Iterators.product(ğ’ª, X)
                    Î·[x, a, o, xâ€²â€²] = Î·[xâ€², a, o, xâ€²â€²]
                end
            end
            push!(removeX,xâ€²)
        end
    end
    # prune identical from previous nodes
    identical_action(x, xâ€²) = all(Ïˆ[x, a] â‰ˆ Ïˆ[xâ€², a] for a in ğ’œ)
    identical_successor(x, xâ€²) = all(Î·[x, a, o, xâ€²â€²] â‰ˆ Î·[xâ€², a, o, xâ€²â€²] for a in ğ’œ, o in ğ’ª, xâ€²â€² in X)
    identical(x, xâ€²) = identical_action(x, xâ€²) && identical_successor(x, xâ€²)
    for (x, xâ€²) in Iterators.product(prevX, newX)
        if xâ€² âˆ‰ removeX && identical(x,xâ€²)
            push!(removeX,xâ€²)
        end
    end
    # prune dominated from new nodes
    for (x, xâ€²) in Iterators.product(X, newX)
        if xâ€² âˆ‰ removeX && dominated(xâ€²,x) && x â‰  xâ€²
            push!(removeX, xâ€²)
        end
    end
    # update controller
    Ï€.X = setdiff(X,removeX)
    Ï€.Ïˆ = Dict(k => v for (k, v) in Ïˆ if k[1] âˆ‰ removeX)
    Ï€.Î· = Dict(k => v for (k, v) in Î· if k[1] âˆ‰ removeX)
end

function solve(M::ControllerPolicyIteration, ğ’«::POMG)
    ğ’œ, ğ’ª, â„, k_max, eval_max = ğ’«.ğ’œ, ğ’«.ğ’ª, length(ğ’«.â„), M.k_max, M.eval_max
    
    X = fill!(Vector{Vector}(undef, â„), [1])
    Ïˆ = Vector{Dict}(undef, â„)
    Î· = Vector{Dict}(undef, â„)

    for i in 1:â„
        Ïˆ[i] = Dict((x, a) => 1.0/length(ğ’œ[i]) for x in X[i], a in ğ’œ[i])
        Î·[i] = Dict((x, a, o, xâ€²)=>1.0 for x in X[i], a in ğ’œ[i], o in ğ’ª[i], xâ€² in X[i])
    end

    Ï€ = ControllerPolicy(ğ’«,X,Ïˆ,Î·) 

    for i in 1:k_max
        prevX = copy(Ï€.X)
        U = iterative_policy_evaluation(Ï€, eval_max)
        policy_improvement!(Ï€, U, prevX)
        prune!(Ï€, U, prevX)
    end
    return Ï€ 
end

M = ControllerPolicyIteration(3,5)
ğ’« = POMG(BabyPOMG())
solve(C,P)